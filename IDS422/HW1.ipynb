{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1. Hyperbolic Tangent Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# tangent func\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# tangent func\n",
    "def tanh(z):\n",
    "    # formula\n",
    "    res = (np.exp(z) - np.exp(-z)) / (np.exp(z) + np.exp(-z))\n",
    "    return res\n",
    "\n",
    "test_inputs = [0, 1, -1, 2, -2]\n",
    "\n",
    "for z in test_inputs:\n",
    "    # calc result\n",
    "    result = tanh(z)\n",
    "    print(f\"tanh({z}) = {result}\")\n",
    "\n",
    "# Plot func\n",
    "x = np.linspace(-5, 5, 1000)\n",
    "y = tanh(x)\n",
    "\n",
    "plt.plot(x, y, label='tanh(z)')\n",
    "plt.xlabel('z')\n",
    "plt.ylabel('tanh(z)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2. Rectified Linear Unit Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mReLU\u001b[39m(z):\n\u001b[1;32m      4\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mmaximum(\u001b[39m0\u001b[39m, z)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def ReLU(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "# scalar, list, numpyArr\n",
    "inputs = [4, [-6, 0, 2, -3], np.array([-3, 4, 5, -1])]\n",
    "\n",
    "for i in range(len(inputs)):\n",
    "    # curr val\n",
    "    input_data = inputs[i]\n",
    "    # calc\n",
    "    result = ReLU(input_data)\n",
    "    \n",
    "    # check to which type current value belongs\n",
    "    if isinstance(input_data, (int, float)):\n",
    "        input_type = \"scalar\"\n",
    "    elif isinstance(input_data, list):\n",
    "        input_type = \"list\"\n",
    "    else:\n",
    "        input_type = \"numpy array\"\n",
    "    # print\n",
    "    print(f\"ReLU activation for {input_type} input {i + 1}:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3. Softmax Activation Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msoftmax\u001b[39m(z):\n\u001b[1;32m      4\u001b[0m     \u001b[39m# calc exponential of each el from z\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     exp_z \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexp(z)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "def softmax(z):\n",
    "    # calc exponential of each el from z\n",
    "    exp_z = np.exp(z)\n",
    "    # sum all calculated vals\n",
    "    sum_exp_z = np.sum(exp_z)\n",
    "\n",
    "    # calc softmax probs\n",
    "    res = exp_z / sum_exp_z\n",
    "\n",
    "    return res\n",
    "\n",
    "def predict(W, x):\n",
    "    # calc dot products\n",
    "    z = np.dot(W, x)\n",
    "\n",
    "    # get all probs\n",
    "    softmax_probs = softmax(z)\n",
    "\n",
    "    # predict class\n",
    "    predicted_class = np.argmax(softmax_probs)\n",
    "    # Return the predicted class\n",
    "    return predicted_class\n",
    "\n",
    "# Test\n",
    "W1 = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "x1 = np.array([0, 1, 2])\n",
    "res1 = predict(W1, x1)\n",
    "print(\"Predicted class for test case 1:\", res1)\n",
    "\n",
    "W2 = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "x2 = np.array([-1, 0, 1])\n",
    "res2 = predict(W2, x2)\n",
    "print(\"Predicted class for test case 2:\", res2)\n",
    "\n",
    "W3 = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "x3 = np.array([1, 0, 1])\n",
    "res3 = predict(W3, x3)\n",
    "print(\"Predicted class for test case 3:\", res3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4. Iris Flower Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n\u001b[1;32m      2\u001b[0m sys\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mappend(\u001b[39m'\u001b[39m\u001b[39m..\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcommon\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimizer\u001b[39;00m \u001b[39mimport\u001b[39;00m SGD\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from common.optimizer import SGD\n",
    "from two_layer_net import TwoLayerNet\n",
    "\n",
    "\n",
    "dataset = pd.read_csv(\"/Users/liza/Desktop/IRIS.csv\")\n",
    "\n",
    "# Getting the data\n",
    "X = dataset.drop('species', axis=1)\n",
    "y = dataset['species']\n",
    "\n",
    "X_train = np.array(pd.concat([X[0:40], X[50:90], X[100:140]]))\n",
    "y_train = np.array(pd.concat([y[0:40], y[50:90], y[100:140]]))\n",
    "\n",
    "X_test = np.array(pd.concat([X[40:50], X[90:100], X[140:150]]))\n",
    "y_test = np.array(pd.concat([y[40:50], y[90:100], y[140:150]]))\n",
    "\n",
    "# Relabel words to indexes\n",
    "species_2_index = {\"Iris-setosa\": 0, \"Iris-versicolor\" : 1, \"Iris-virginica\" : 2}\n",
    "y_train = np.array([species_2_index[species] for species in y_train])\n",
    "y_test = np.array([species_2_index[species] for species in y_test])\n",
    "\n",
    "# Normalize the data by applying the Z-score normalization\n",
    "X_train = (X_train - np.mean(X_train, axis=0)) / np.std(X_train, axis=0)\n",
    "X_test = (X_test - np.mean(X_test, axis=0)) / np.std(X_test, axis=0)\n",
    "\n",
    "# Now data is in np arrays:\n",
    "# Train:\n",
    "# X_train.shape = (120, 4) = (num_examples, num_features)\n",
    "# y_train.shape = (120,) = (num_examples, )\n",
    "# Test:\n",
    "# X_test.shape = (30, 4) = (num_examples, num_features)\n",
    "# y_test.shape = (30,) = (num_examples, )\n",
    "\n",
    "\n",
    "# Constructing a 2-layer net\n",
    "neural_net = TwoLayerNet(4, 5, 3)\n",
    "\n",
    "# Training\n",
    "\n",
    "# Hyperparameters\n",
    "max_epoch = 100\n",
    "batch_size = 40\n",
    "learning_rate = 0.5\n",
    "\n",
    "optimizer = SGD(lr=learning_rate)\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "\n",
    "    # Shuffle data\n",
    "    idx = np.random.permutation(X_train.shape[0])\n",
    "    X_epoch = X_train[idx]\n",
    "    y_epoch = y_train[idx]\n",
    "\n",
    "    # print(X_epoch)\n",
    "    # print(y_epoch)\n",
    "\n",
    "    for iters in range(X_train.shape[0] // batch_size):\n",
    "        batch_X = X_epoch[iters*batch_size : (iters+1)*batch_size]\n",
    "        batch_y = y_epoch[iters*batch_size : (iters+1)*batch_size]\n",
    "        \n",
    "        # compute gradients, update parameters\n",
    "        loss = neural_net.forward(batch_X, batch_y)\n",
    "        neural_net.backward()\n",
    "        optimizer.update(neural_net.params, neural_net.grads)\n",
    "        print(loss)\n",
    "\n",
    "\n",
    "# Making predictions\n",
    "y_pred = np.argmax(neural_net.predict(X_test), axis=1)\n",
    "\n",
    "# Computing accuracy\n",
    "classification_error = np.sum(np.array([1 for pred, true in zip (y_pred, y_test) if pred == true])) / y_test.shape[0]\n",
    "\n",
    "print(f\"Error is {1 - classification_error}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
